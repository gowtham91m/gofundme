# -*- coding: utf-8 -*-
"""process.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FaODQc7JqvgvCn2oEwNnsublO-Hmh7nv
"""

import pandas as pd
import re
import nltk
from nltk import word_tokenize
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords

class clean_data():
  def __init__(self):
    self.text_columns = ['category','title','city','state','text']
    self.num_cols_to_clean = ['goal','raised','likes','shares','donation_count']
    
  def str_to_num(self,x):
      x = re.sub('[,\$\.]','',x)
      x = re.sub('M','000000',x)
      x = re.sub('k','000',x)
      return x
    
  def remove_stop_words(self,x):
    stop_words = set(stopwords.words('english'))
    x_words = word_tokenize(x)
    x_words = [i for i in x_words if not i in stop_words]
    return ' '.join(x_words)

  def text_process(self,x):
    x = x.lower()
    # replace non alpha numerical characters with space character
    x = re.sub('[^a-z0-9]',' ',x)
    
    # replace multiple spaceses with single space 
    x = re.sub('(  +)', ' ', x)
    
    # remove stop words
    x = self.remove_stop_words(x)
    return x
  
  def process(self,df):
    df[self.num_cols_to_clean] = df[self.num_cols_to_clean].applymap(self.str_to_num)
    df = df.join(df['location'].str.split(',', 1, expand=True).rename(columns={0:'city', 1:'state'}))
    df[self.text_columns] = df[self.text_columns].applymap(self.text_process)
    df.drop(['location','href'],inplace=True,axis=1)
    
    return df

campaigns = pd.read_csv('https://raw.githubusercontent.com/gowtham91m/gofundme/master/data/medical.csv')
campaigns = clean_data().process(campaigns)

campaigns.head()